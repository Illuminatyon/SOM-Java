# Self Organizing Map

![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![Universit√©: Paris 8](https://img.shields.io/badge/Universit√©-Paris%208-blue)
![Machine: learning](https://img.shields.io/badge/Machine-Learning-orange)
![Java: 17](https://img.shields.io/badge/Java-17-red)
![Contributeurs](https://img.shields.io/badge/Contributeurs-1-brightgreen)
![√âtoiles](https://img.shields.io/badge/√âtoiles-0-lightgrey)
![Forks](https://img.shields.io/badge/Forks-0-lightgrey)
![Observateurs](https://img.shields.io/badge/Observateurs-0-lightgrey)

## üåç Versions multilingues du README

- üá´üá∑ Fran√ßais (vous √™tes ici)
- üá¨üáß [English](README.md)
- üá™üá∏ [Espa√±ol](README.es.md)

## üìò Aper√ßu du projet

Ce projet est une impl√©mentation simplifi√©e d'une Carte Auto-Organisatrice (SOM) d√©velopp√©e par passion pour les math√©matiques et par int√©r√™t pour int√©grer une grande √©cole d'ing√©nieur. L'objectif principal √©tait de comprendre le fonctionnement de l'algorithme SOM en recr√©ant une version √† partir de z√©ro avec les contraintes suivantes :

- Aucune variable globale utilis√©e.
- Les BMU (Best Matching Units) sont stock√©es dans une liste cha√Æn√©e.
- La taille des collections : matrices et listes cha√Æn√©es doivent √™tre calcul√©es dynamiquement.

## üìä Jeu de donn√©es

Le jeu de donn√©es utilis√© est le jeu de donn√©es Iris, disponible sur Kaggle :
[Jeu de donn√©es Iris](https://www.kaggle.com/datasets/uciml/iris)

- 150 √©chantillons
- 4 caract√©ristiques par √©chantillon :
  - Longueur du s√©pale
  - Largeur du s√©pale
  - Longueur du p√©tale
  - Largeur du p√©tale
- 3 classes :
  - Iris-setosa
  - Iris-versicolor
  - Iris-virginica

## ‚öôÔ∏è Fonctionnement de l'algorithme SOM

La Carte Auto-Organisatrice (SOM) est un r√©seau de neurones non supervis√© utilis√© pour la r√©duction de dimensionnalit√© et la visualisation de donn√©es. Voici les principales √©tapes :

1. **Initialisation**
   Les neurones de la carte sont initialis√©s al√©atoirement dans l'espace des caract√©ristiques.

2. **Calcul de distance**
   Pour chaque donn√©e d'entr√©e, la distance euclidienne entre cette donn√©e et tous les neurones est calcul√©e.
   Le neurone avec la plus petite distance est appel√© BMU (Best Matching Unit). Ce processus suit le principe du Winner-Takes-All (WTA), o√π seul le neurone le plus proche de la donn√©e d'entr√©e est s√©lectionn√©, ainsi que ses voisins.

3. **Mise √† jour de la carte**
   Le BMU et ses voisins sont ajust√©s pour se rapprocher de la donn√©e d'entr√©e, selon un taux d'apprentissage Œ±. Cela ajuste progressivement la carte pour mieux repr√©senter les donn√©es d'entr√©e.

4. **It√©ration**
   Les √©tapes 2 √† 3 sont r√©p√©t√©es pour un nombre d√©fini d'it√©rations.
   - Le taux d'apprentissage diminue avec le temps.
   - La taille du voisinage se r√©duit progressivement, permettant √† la carte de se sp√©cialiser tout en maintenant une coh√©rence topologique.

Le r√©sultat est une carte organis√©e topologiquement, o√π des classes similaires se trouvent dans des zones proches. L'algorithme SOM regroupe ainsi des donn√©es similaires tout en pr√©servant leur structure.

## üßë‚Äçüíª Technologies utilis√©es

- Langage : Java (impl√©mentation √† partir de z√©ro)

## üíª Installer Java (si vous n'avez pas Java install√©)

Si vous n'avez pas Java install√©, vous pouvez suivre les instructions dans l'une de mes vid√©os YouTube pour installer Java sur diff√©rentes plateformes :

- Linux : [Installer Java sur Linux](https://www.youtube.com/watch?v=example1)
- Mac : [Installer Java sur Mac](https://www.youtube.com/watch?v=example2)
- Windows : [Installer Java sur Windows](https://www.youtube.com/watch?v=example3)

## üìù Compilation et ex√©cution

### Cloner le d√©p√¥t

```bash
git clone https://github.com/Fab16BSB/SOM_JAVA.git
cd SOM_JAVA
```

### Compilation

```bash
javac -d bin src/main/java/com/fabio/som/*.java
```

### Ex√©cution

```bash
java -cp bin com.fabio.som.SOMApplication data/test_data.csv
```

## üìà R√©sultats

Lorsque vous ex√©cutez l'application, vous verrez le processus d'entra√Ænement SOM et la classification r√©sultante du jeu de donn√©es Iris. La sortie affichera :

1. Chargement et normalisation des donn√©es
2. Calcul du vecteur moyen
3. Cr√©ation de vecteurs de poids al√©atoires
4. G√©n√©ration de la grille de neurones
5. Entra√Ænement SOM
6. Attribution et visualisation des √©tiquettes de classe

La sortie finale affichera une grille de neurones avec leurs classes assign√©es, montrant comment le SOM a organis√© les donn√©es en clusters.

## Composants

L'impl√©mentation se compose de quatre classes principales :

1. **DataPoint** : Repr√©sente un point de donn√©es multidimensionnel avec des caract√©ristiques num√©riques et une √©tiquette optionnelle.
2. **Neuron** : Repr√©sente un n≈ìud dans la grille SOM, contenant un vecteur de poids et une position.
3. **SOMProcessor** : Moteur de traitement principal qui g√®re la normalisation des donn√©es, l'entra√Ænement SOM et la classification.
4. **SOMApplication** : Classe d'application principale fournissant une interface en ligne de commande.

## D√©tails d'impl√©mentation

### Algorithme d'entra√Ænement SOM

Le processus d'entra√Ænement suit ces √©tapes :

1. Initialiser une grille de neurones avec des vecteurs de poids al√©atoires
2. Pour chaque vecteur d'entr√©e :
   - Trouver la Best Matching Unit (BMU) - le neurone avec le vecteur de poids le plus proche
   - Mettre √† jour les vecteurs de poids du BMU et de ses voisins pour les rapprocher du vecteur d'entr√©e
3. R√©duire progressivement le taux d'apprentissage et la taille du voisinage
4. Attribuer des √©tiquettes de classe aux neurones en fonction des vecteurs d'entr√©e les plus proches

### Param√®tres

- **Bornes sup√©rieure/inf√©rieure** : Contr√¥lent la plage d'initialisation al√©atoire des poids
- **Mode d'entra√Ænement** : S√©quentiel (0) ou Al√©atoire (1)
- **Taux d'apprentissage** : Commence √† 0,7 et diminue jusqu'√† 0,07 pendant l'entra√Ænement
- **Rayon de voisinage** : Commence √† 3 et diminue jusqu'√† 1 pendant l'entra√Ænement

## R√©f√©rences

- Kohonen, T. (1982). Self-organized formation of topologically correct feature maps. Biological Cybernetics, 43(1), 59-69.
- Kohonen, T. (1990). The self-organizing map. Proceedings of the IEEE, 78(9), 1464-1480.
